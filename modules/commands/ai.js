const axios = require("axios");
const fs = require("fs-extra");
const path = require("path");

// Ki·ªÉm tra th∆∞ vi·ªán @google/generative-ai ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t ch∆∞a
let useGemini = false;
let GoogleGenerativeAI;
try {
  GoogleGenerativeAI = require('@google/generative-ai');
  useGemini = true;
} catch (error) {
  console.warn("Th∆∞ vi·ªán @google/generative-ai kh√¥ng c√≥ s·∫µn, s·∫Ω s·ª≠ d·ª•ng OpenAI API");
}

module.exports.config = {
  name: "ai",
  version: "1.0.1",
  hasPermssion: 0,
  credits: "LunarKrystal",
  description: "Chat v·ªõi AI (GPT-3.5-turbo ho·∫∑c Google Gemini)",
  commandCategory: "Ti·ªán √≠ch",
  usages: "[n·ªôi dung c·∫ßn h·ªèi]",
  cooldowns: 5,
  dependencies: {
    "axios": "",
    "fs-extra": "",
    "@google/generative-ai": ""
  }
};

// C·∫•u h√¨nh API keys - thay ƒë·ªïi trong file n√†y ho·∫∑c t·∫°o file config
const configPath = path.join(__dirname, 'cache', 'ai_config.json');
let config = {
  openaiApiKey: "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", // Thay b·∫±ng API key OpenAI c·ªßa b·∫°n
  geminiApiKey: "AIzaSyC24jumviNdxX3wplx4fQ9PTdMdvmkMHvE", // Thay b·∫±ng API key Gemini c·ªßa b·∫°n
  defaultModel: "openai" // ho·∫∑c "openai"
};

// T·∫°o ho·∫∑c ƒë·ªçc file c·∫•u h√¨nh
if (fs.existsSync(configPath)) {
  try {
    config = { ...config, ...JSON.parse(fs.readFileSync(configPath, 'utf8')) };
  } catch (error) {
    console.error("L·ªói khi ƒë·ªçc file c·∫•u h√¨nh AI:", error);
  }
} else {
  if (!fs.existsSync(path.join(__dirname, 'cache'))) {
    fs.mkdirSync(path.join(__dirname, 'cache'), { recursive: true });
  }
  fs.writeFileSync(configPath, JSON.stringify(config, null, 2), 'utf8');
}

// L∆∞u tr·ªØ l·ªãch s·ª≠ chat c·ªßa m·ªói ng∆∞·ªùi d√πng
const conversationHistory = {};
const HISTORY_LENGTH = 4; // Gi·ªØ l·∫°i 4 l∆∞·ª£t t∆∞∆°ng t√°c g·∫ßn nh·∫•t
const MAX_TOKENS = 500; // Gi·ªõi h·∫°n ƒë·ªô d√†i c√¢u tr·∫£ l·ªùi

// H√†m x√≥a l·ªãch s·ª≠ chat
function clearHistory(userID) {
  if (conversationHistory[userID]) {
    conversationHistory[userID] = [];
    return true;
  }
  return false;
}

// H√†m kh·ªüi t·∫°o ho·∫∑c l·∫•y l·ªãch s·ª≠ chat
function getHistory(userID) {
  if (!conversationHistory[userID]) {
    conversationHistory[userID] = [];
  }
  return conversationHistory[userID];
}

// H√†m th√™m tin nh·∫Øn v√†o l·ªãch s·ª≠
function addToHistory(userID, role, content) {
  const history = getHistory(userID);
  history.push({ role, content });
  
  // Gi·ªØ l·ªãch s·ª≠ ch·ªâ v·ªõi HISTORY_LENGTH tin nh·∫Øn g·∫ßn nh·∫•t
  while (history.length > HISTORY_LENGTH * 2) { // *2 v√¨ m·ªói l∆∞·ª£t c√≥ 2 tin nh·∫Øn (user v√† assistant)
    history.shift();
  }
}

// H√†m truy v·∫•n OpenAI
async function queryOpenAI(userMessage, userID) {
  // Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
  addToHistory(userID, "user", userMessage);

  // Chu·∫©n b·ªã tin nh·∫Øn ƒë·ªÉ g·ª≠i ƒë·∫øn API
  const messages = [
    { role: "system", content: "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh, nhi·ªát t√¨nh v√† h·ªØu √≠ch. H√£y tr·∫£ l·ªùi m·ªôt c√°ch ch√≠nh x√°c, ƒë·∫ßy ƒë·ªß nh∆∞ng ng·∫Øn g·ªçn trong kho·∫£ng 50-300 t·ª´. N·∫øu b·∫°n kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, h√£y n√≥i th·∫≠t l√† b·∫°n kh√¥ng bi·∫øt. B·∫°n ƒë∆∞·ª£c t·∫°o b·ªüi OpenAI." },
    ...getHistory(userID)
  ];

  // G·ªçi API OpenAI
  const response = await axios.post("https://api.openai.com/v1/chat/completions", {
    model: "gpt-3.5-turbo",
    messages: messages,
    max_tokens: MAX_TOKENS,
    temperature: 0.7,
  }, {
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${config.openaiApiKey}`
    }
  });

  // L·∫•y c√¢u tr·∫£ l·ªùi
  const aiResponse = response.data.choices[0].message.content.trim();
  
  // Th√™m c√¢u tr·∫£ l·ªùi v√†o l·ªãch s·ª≠
  addToHistory(userID, "assistant", aiResponse);
  
  return aiResponse;
}

// H√†m truy v·∫•n Gemini
async function queryGemini(userMessage, userID) {
  // Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
  addToHistory(userID, "user", userMessage);

  // Kh·ªüi t·∫°o API Gemini
  const genAI = new GoogleGenerativeAI(config.geminiApiKey);
  const model = genAI.getGenerativeModel({ model: "gemini-pro" });

  // Chu·∫©n b·ªã l·ªãch s·ª≠ ƒë·ªÉ g·ª≠i API
  let chatHistory = getHistory(userID).map(msg => ({
    role: msg.role === "user" ? "user" : "model",
    parts: [{ text: msg.content }]
  }));

  // T·∫°o chat session
  const chat = model.startChat({
    history: chatHistory.slice(0, -1), // Kh√¥ng bao g·ªìm tin nh·∫Øn cu·ªëi c√πng (s·∫Ω g·ª≠i d∆∞·ªõi d·∫°ng prompt)
    generationConfig: {
      maxOutputTokens: MAX_TOKENS,
      temperature: 0.7,
    },
  });

  // G·ª≠i tin nh·∫Øn m·ªõi nh·∫•t v√† nh·∫≠n ph·∫£n h·ªìi
  const latestMessage = chatHistory[chatHistory.length - 1];
  const result = await chat.sendMessage(latestMessage.parts[0].text);
  const aiResponse = result.response.text();

  // Th√™m c√¢u tr·∫£ l·ªùi v√†o l·ªãch s·ª≠
  addToHistory(userID, "assistant", aiResponse);
  
  return aiResponse;
}

module.exports.run = async function({ api, event, args }) {
  const { threadID, messageID, senderID } = event;
  const content = args.join(" ");

  if (!content) {
    return api.sendMessage("Vui l√≤ng nh·∫≠p n·ªôi dung c·∫ßn h·ªèi AI!", threadID, messageID);
  }

  // X·ª≠ l√Ω l·ªánh ƒë·∫∑c bi·ªát
  if (content.toLowerCase() === "clear") {
    const cleared = clearHistory(senderID);
    return api.sendMessage(cleared ? "ƒê√£ x√≥a l·ªãch s·ª≠ chat c·ªßa b·∫°n!" : "B·∫°n ch∆∞a c√≥ l·ªãch s·ª≠ chat n√†o!", threadID, messageID);
  }
  
  if (content.toLowerCase().startsWith("switch")) {
    const model = content.toLowerCase().replace("switch", "").trim();
    if (model === "openai" || model === "gemini") {
      config.defaultModel = model;
      fs.writeFileSync(configPath, JSON.stringify(config, null, 2), 'utf8');
      return api.sendMessage(`ƒê√£ chuy·ªÉn sang s·ª≠ d·ª•ng model ${model.toUpperCase()}!`, threadID, messageID);
    } else {
      return api.sendMessage("Model kh√¥ng h·ª£p l·ªá. Vui l√≤ng ch·ªçn 'openai' ho·∫∑c 'gemini'!", threadID, messageID);
    }
  }

  // B√°o ng∆∞·ªùi d√πng ch·ªù
  api.sendMessage(`ü§ñ AI ƒëang x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n (s·ª≠ d·ª•ng ${config.defaultModel.toUpperCase()})...`, threadID, messageID);

  try {
    let aiResponse;
    
    // Ch·ªçn model ƒë·ªÉ s·ª≠ d·ª•ng
    if (config.defaultModel === "gemini" && useGemini) {
      aiResponse = await queryGemini(content, senderID);
    } else {
      aiResponse = await queryOpenAI(content, senderID);
    }

    // G·ª≠i c√¢u tr·∫£ l·ªùi cho ng∆∞·ªùi d√πng
    api.sendMessage(`ü§ñ AI: ${aiResponse}`, threadID, messageID);
  } catch (error) {
    console.error("L·ªói khi truy v·∫•n AI:", error);
    if (error.response) {
      console.error("Response error:", error.response.data);
    }
    api.sendMessage(`‚ùå ƒê√£ x·∫£y ra l·ªói khi truy v·∫•n AI (${config.defaultModel}). Vui l√≤ng th·ª≠ l·∫°i sau!`, threadID, messageID);
  }
}; 
